{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import scipy.sparse as sparse\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '/Users/appry001/Data/ml-20m/pro/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_uid = list()\n",
    "with open(os.path.join(DATA_DIR, 'unique_uid.txt'), 'r') as f:\n",
    "    for line in f:\n",
    "        unique_uid.append(line.strip())\n",
    "    \n",
    "unique_sid = list()\n",
    "with open(os.path.join(DATA_DIR, 'unique_sid.txt'), 'r') as f:\n",
    "    for line in f:\n",
    "        unique_sid.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111148 11711\n"
     ]
    }
   ],
   "source": [
    "n_items = len(unique_sid)\n",
    "n_users = len(unique_uid)\n",
    "\n",
    "print(n_users, n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(csv_file, shape=(n_users, n_items)):\n",
    "    tp = pd.read_csv(csv_file)\n",
    "    timestamps, rows, cols = np.array(tp['timestamp']), np.array(tp['uid']), np.array(tp['sid'])\n",
    "    #seq = np.concatenate((rows[:, None], cols[:, None], np.ones((rows.size, 1), dtype='int'), timestamps[:, None]), axis=1)\n",
    "    data = sparse.csr_matrix((np.ones_like(rows), (rows, cols)), dtype=np.int16, shape=shape)\n",
    "    return data #, seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = load_data(os.path.join(DATA_DIR, 'train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vad_data = load_data(os.path.join(DATA_DIR, 'validation.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = load_data(os.path.join(DATA_DIR, 'test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def linear_surplus_confidence_matrix(B, alpha):\n",
    "    S = B.copy()\n",
    "    S.data = alpha * S.data\n",
    "    return S\n",
    "\n",
    "def log_surplus_confidence_matrix(B, alpha, epsilon):\n",
    "    S = B.copy()\n",
    "    S.data = alpha * np.log(1 + S.data / epsilon)\n",
    "    return S\n",
    "\n",
    "def recall_k(p_pred, p_true, k=50):\n",
    "    # p_hat -> p_pred\n",
    "    # p_vad -> p_true\n",
    "    m, n = p_pred.shape\n",
    "    recall = 0\n",
    "    N = m\n",
    "    for u in range(m):\n",
    "        p_true_u = p_true[u].T.toarray().reshape(n)\n",
    "        nnz = np.sum(p_true_u)\n",
    "        if nnz < 1:\n",
    "            N -=1\n",
    "            continue\n",
    "        p_pred_u = p_pred[u]\n",
    "        topk = np.argsort(p_pred_u)[-k:]\n",
    "        tmp_val = np.sum(p_true_u[topk]) / min(nnz, k)\n",
    "        if tmp_val > 1:\n",
    "            return p_true_u, topk, nnz, k\n",
    "        recall += tmp_val\n",
    "    return recall / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fixed_ALS_update(counts, fix_vectors, user_update=True, n_factors=10, lambda_=0.01):\n",
    "    '''\n",
    "    Args:\n",
    "        counts: sparse csr matrix of user/item consumption counts e_ui: user u consumed item i e_ui times\n",
    "        fix_vectors: np.ndarray of either item/user features; n_items/n_users by n_factors\n",
    "        user_update: bool to determine if this will update user or item factor vectors\n",
    "        n_factors: the number of latent variables to describe users and items\n",
    "        lambda_: the regularization of the user and item factor vectors.\n",
    "    Returns:\n",
    "        solve_vecs: np.ndarray of either user/item features\n",
    "        \n",
    "    Notes:\n",
    "        Implicit matrix factorization predicts preferences by using the confidence and preference of each\n",
    "        user consuming items where counts[u] denotes the consumption of all items, viz.\n",
    "        pref[u] = 1 if counts[u] > 0 else 0.\n",
    "        conf[u] = 1 + alpha * counts[u].\n",
    "        Unobserved values(zeroes in counts[u]) get confidence 1 and observed values get confidense\n",
    "        proportional to counts[u].\n",
    "        \n",
    "        Using alternating least squares (ALS), we solve the linear system,\n",
    "        (YTCuY + lambda_I) xu = YTCupu,\n",
    "        where YT is Y.transpose and Cu is a diagonal matrix with conf[u] along the diagonal.\n",
    "        Because conf[u] is dense, the diagonal of Cu will also be dense.\n",
    "        To speed up the solution to the linear system, we do not use Cu or YTCuY and compose instead\n",
    "        {YTY + YT(Cu-I)Y + lambda_I} xu = YT(Cu-I+I)Y\n",
    "        The precomputation of YTY computation of Cu-I, `Cu_minus_I`, for each user makes our solution\n",
    "        scale with only the observed counts. Concretely, while the initial YTCuY computation would \n",
    "        scale with n_items for each user, computation of YT(Cu-I)Y scales with n_i,\n",
    "        the number of items user u consumed, n_i << n_items.\n",
    "        \n",
    "    '''\n",
    "    m, n = counts.shape\n",
    "    num_solve = m if user_update else n\n",
    "    \n",
    "    fixed = sparse.csr_matrix(fix_vectors)\n",
    "    num_fixed = fixed.shape[0]\n",
    "\n",
    "    solve_vecs = np.zeros((num_solve, n_factors))\n",
    "    \n",
    "    # precompute user independent objects\n",
    "    YTY = np.dot(fixed.T, fixed)\n",
    "    eye = sparse.eye(num_fixed)\n",
    "    lambda_eye = lambda_ * sparse.eye(n_factors)\n",
    "\n",
    "    for u in xrange(num_solve):\n",
    "        if user_update:\n",
    "            c_u = counts[u].toarray()\n",
    "        else:\n",
    "            c_u = counts[:, u].T.toarray()\n",
    "        pu = c_u.copy()\n",
    "        pu[np.where(pu != 0)] = 1.0\n",
    "        \n",
    "        Cu_minus_I = sparse.diags(c_u, [0])        \n",
    "        YTCuIY = fixed.T.dot(Cu_minus_I).dot(fixed)\n",
    "        YTCupu = fixed.T.dot(Cu_minus_I + eye).dot(sparse.csr_matrix(pu).T)\n",
    "        xu = spsolve(YTY + YTCuIY + lambda_eye, YTCupu)\n",
    "        solve_vecs[u] = xu\n",
    "        \n",
    "    return solve_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(111148, 10) (11711, 10)\n"
     ]
    }
   ],
   "source": [
    "n_factors = 10\n",
    "num_iterations = 3\n",
    "lambda_ = 1e-5\n",
    "\n",
    "alpha = 10\n",
    "counts = linear_surplus_confidence_matrix(train_data, alpha)\n",
    "\n",
    "# random init of user/item factors\n",
    "user_vectors = np.random.normal(size=(n_users, n_factors))\n",
    "item_vectors = np.random.normal(size=(n_items, n_factors))\n",
    "\n",
    "print(user_vectors.shape, item_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<111148x11711 sparse matrix of type '<type 'numpy.int16'>'\n",
       "\twith 207161 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_train = train_data.copy()\n",
    "p_train.data = np.ones_like(train_data.data)\n",
    "p_train\n",
    "\n",
    "p_vad = vad_data.copy()\n",
    "p_vad.data = np.ones_like(vad_data.data)\n",
    "p_vad\n",
    "\n",
    "p_test = test_data.copy()\n",
    "p_test.data = np.ones_like(test_data.data)\n",
    "p_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tUser update...455.45s \n",
      "\tItem update...494.35s \n",
      "Recall@50= 0.348\n",
      "\tUser update...453.1s \n",
      "\tItem update...495.69s \n",
      "Recall@50= 0.365\n",
      "\tUser update...451.1s \n",
      "\tItem update...500.1s \n",
      "Recall@50= 0.368\n"
     ]
    }
   ],
   "source": [
    "for _ in xrange(num_iterations):\n",
    "    t = time.time()\n",
    "    user_vectors = fixed_ALS_update(\n",
    "        counts, item_vectors, True, n_factors=n_factors, lambda_=lambda_)\n",
    "    print('\\tUser update...{0:5.5}s '.format(time.time() - t))\n",
    "    t = time.time()\n",
    "    item_vectors = fixed_ALS_update(\n",
    "        counts, user_vectors, False, n_factors=n_factors, lambda_=lambda_)\n",
    "    print('\\tItem update...{0:5.5}s '.format(time.time() - t))\n",
    "    \n",
    "    # calc metric\n",
    "    p_pred = user_vectors.dot(item_vectors.T)\n",
    "    score = recall_k(p_pred, p_vad, k=50)\n",
    "    print('Recall@50= {0:.3}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@50= 0.185\n"
     ]
    }
   ],
   "source": [
    "# calc metric\n",
    "p_pred = user_vectors.dot(item_vectors.T)\n",
    "score = recall_k(p_pred, p_vad, k=50)\n",
    "print('Recall@50= {0:.3}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@50= 0.0956\n"
     ]
    }
   ],
   "source": [
    "# calc metric\n",
    "p_pred = user_vectors.dot(item_vectors.T)\n",
    "score = recall_k(p_pred, p_test, k=50)\n",
    "print('Recall@50= {0:.3}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
